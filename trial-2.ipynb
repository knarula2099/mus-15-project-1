{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaleido in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.10.13/lib/python3.10/site-packages (4.66.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U kaleido\n",
    "%pip install tqdm\n",
    "\n",
    "# Configuration\n",
    "FPS = 30\n",
    "FFT_WINDOW_SECONDS = 0.25 # how many seconds of audio make up an FFT window\n",
    "\n",
    "# Note range to display\n",
    "FREQ_MIN = 10\n",
    "FREQ_MAX = 1000\n",
    "\n",
    "# Notes to display\n",
    "TOP_NOTES = 3\n",
    "\n",
    "# Names of the notes\n",
    "NOTE_NAMES = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n",
    "\n",
    "# Output size. Generally use SCALE for higher res, unless you need a non-standard aspect ratio.\n",
    "RESOLUTION = (1920, 1080)\n",
    "SCALE = 2 # 0.5=QHD(960x540), 1=HD(1920x1080), 2=4K(3840x2160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft\n",
    "from scipy.io import wavfile # get the api\n",
    "import os\n",
    "\n",
    "AUDIO_FILE = \"c-scale-demo.wav\"\n",
    "\n",
    "fs, data = wavfile.read(AUDIO_FILE) # load the data\n",
    "\n",
    "# Check if the audio data has more than one channel\n",
    "if len(data.shape) > 1 and data.shape[1] > 1:\n",
    "    audio = data.T[0] # this is a two channel soundtrack, get the first track\n",
    "else:\n",
    "    audio = data # this is a mono soundtrack\n",
    "\n",
    "FRAME_STEP = (fs / FPS) # audio samples per video frame\n",
    "FFT_WINDOW_SIZE = int(fs * FFT_WINDOW_SECONDS)\n",
    "AUDIO_LENGTH = len(audio)/fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_fft(p, xf, fs, notes, dimensions=(960,540)):\n",
    "  layout = go.Layout(\n",
    "      title=\"frequency spectrum\",\n",
    "      autosize=False,\n",
    "      width=dimensions[0],\n",
    "      height=dimensions[1],\n",
    "      xaxis_title=\"Frequency (note)\",\n",
    "      yaxis_title=\"Magnitude\",\n",
    "      font={'size' : 24}\n",
    "  )\n",
    "\n",
    "  fig = go.Figure(layout=layout,\n",
    "                  layout_xaxis_range=[FREQ_MIN,FREQ_MAX],\n",
    "                  layout_yaxis_range=[0,1]\n",
    "                  )\n",
    "  \n",
    "  fig.add_trace(go.Scatter(\n",
    "      x = xf,\n",
    "      y = p))\n",
    "  \n",
    "  for note in notes:\n",
    "    fig.add_annotation(x=note[0]+10, y=note[2],\n",
    "            text=note[1],\n",
    "            font = {'size' : 48},\n",
    "            showarrow=False)\n",
    "  return fig\n",
    "\n",
    "def extract_sample(audio, frame_number):\n",
    "  end = frame_number * FRAME_OFFSET\n",
    "  begin = int(end - FFT_WINDOW_SIZE)\n",
    "\n",
    "  if end == 0:\n",
    "    # We have no audio yet, return all zeros (very beginning)\n",
    "    return np.zeros((np.abs(begin)),dtype=float)\n",
    "  elif begin<0:\n",
    "    # We have some audio, padd with zeros\n",
    "    return np.concatenate([np.zeros((np.abs(begin)),dtype=float),audio[0:end]])\n",
    "  else:\n",
    "    # Usually this happens, return the next sample\n",
    "    return audio[begin:end]\n",
    "\n",
    "def find_top_notes(fft,num):\n",
    "  if np.max(fft.real)<0.001:\n",
    "    return []\n",
    "\n",
    "  lst = [x for x in enumerate(fft.real)]\n",
    "  lst = sorted(lst, key=lambda x: x[1],reverse=True)\n",
    "\n",
    "  idx = 0\n",
    "  found = []\n",
    "  found_note = set()\n",
    "  while( (idx<len(lst)) and (len(found)<num) ):\n",
    "    f = xf[lst[idx][0]]\n",
    "    y = lst[idx][1]\n",
    "    n = freq_to_number(f)\n",
    "    n0 = int(round(n))\n",
    "    name = note_name(n0)\n",
    "\n",
    "    if name not in found_note:\n",
    "      found_note.add(name)\n",
    "      s = [f,note_name(n0),y]\n",
    "      found.append(s)\n",
    "    idx += 1\n",
    "    \n",
    "  return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max amplitude: 31356926.787363894\n",
      "Producing frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/223 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:47<00:00,  4.74it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "# See https://newt.phys.unsw.edu.au/jw/notes.html\n",
    "def freq_to_number(f): return 69 + 12*np.log2(f/440.0)\n",
    "def number_to_freq(n): return 440 * 2.0**((n-69)/12.0)\n",
    "def note_name(n): return NOTE_NAMES[n % 12] + str(int(n/12 - 1))\n",
    "\n",
    "# Hanning window function\n",
    "window = 0.5 * (1 - np.cos(np.linspace(0, 2*np.pi, FFT_WINDOW_SIZE, False)))\n",
    "\n",
    "xf = np.fft.rfftfreq(FFT_WINDOW_SIZE, 1/fs)\n",
    "FRAME_COUNT = int(AUDIO_LENGTH*FPS)\n",
    "FRAME_OFFSET = int(len(audio)/FRAME_COUNT)\n",
    "\n",
    "# Pass 1, find out the maximum amplitude so we can scale.\n",
    "mx = 0\n",
    "for frame_number in range(FRAME_COUNT):\n",
    "  sample = extract_sample(audio, frame_number)\n",
    "\n",
    "  fft = np.fft.rfft(sample * window)\n",
    "  fft = np.abs(fft).real \n",
    "  mx = max(np.max(fft),mx)\n",
    "\n",
    "print(f\"Max amplitude: {mx}\")\n",
    "\n",
    "# Pass 2, produce the animation\n",
    "print(\"Producing frames...\")\n",
    "for frame_number in tqdm.tqdm(range(FRAME_COUNT)):\n",
    "  sample = extract_sample(audio, frame_number)\n",
    "\n",
    "  fft = np.fft.rfft(sample * window)\n",
    "  fft = np.abs(fft) / mx \n",
    "     \n",
    "  s = find_top_notes(fft,TOP_NOTES)\n",
    "\n",
    "  fig = plot_fft(fft.real,xf,fs,s,RESOLUTION)\n",
    "  fig.write_image(f\"frames/frame{frame_number}.png\",scale=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, image2, from 'frames/frame%d.png':\n",
      "  Duration: 00:00:07.43, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: png, rgba(pc), 3840x2160, 30 fps, 30 tbr, 30 tbn, 30 tbc\n",
      "\u001b[0;33mGuessed Channel Layout for Input Stream #1.0 : mono\n",
      "\u001b[0mInput #1, wav, from 'c-scale-demo.wav':\n",
      "  Metadata:\n",
      "    title           : The Village at Torrey Pines East #1\n",
      "    encoder         : Lavf60.3.100\n",
      "  Duration: 00:00:07.45, bitrate: 768 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, mono, s16, 768 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "  Stream #1:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[0;35m[image2 @ 0x5fdf0c1b1880] \u001b[0m\u001b[0;33mThread message queue blocking; consider raising the thread_queue_size option (current value: 8)\n",
      "\u001b[0m\u001b[1;36m[libx264 @ 0x5fdf0c201e00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
      "\u001b[1;36m[libx264 @ 0x5fdf0c201e00] \u001b[0mprofile High, level 5.1\n",
      "\u001b[1;36m[libx264 @ 0x5fdf0c201e00] \u001b[0m264 - core 155 r2917 0a84d98 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'demo-movie.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p(progressive), 3840x2160, q=-1--1, 30 fps, 15360 tbn, 30 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "    Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 69 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "frame=   38 fps= 14 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    \r"
     ]
    }
   ],
   "source": [
    "!ffmpeg -y -r {FPS} -f image2 -s 1920x1080 -i frames/frame%d.png -i {AUDIO_FILE} -c:v libx264 -pix_fmt yuv420p demo-movie.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
